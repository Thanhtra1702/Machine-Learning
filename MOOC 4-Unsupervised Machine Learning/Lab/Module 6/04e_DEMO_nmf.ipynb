{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc_ANwiUvMFt"
      },
      "source": [
        "<center>\n",
        "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"cognitiveclass.ai logo\">\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "marked": true
        },
        "id": "5uCt8oKBvMFw"
      },
      "source": [
        "# Machine Learning Foundation\n",
        "\n",
        "## Course 4, Part e: Non-Negative Matrix Factorization DEMO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7l6VasDvMFw"
      },
      "source": [
        "This exercise illustrates usage of Non-negative Matrix factorization and covers techniques related to sparse matrices and some basic work with Natural Langauge Processing.  We will use NMF to look at the top words for given topics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h12A9Mm7vMFx"
      },
      "source": [
        "## Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT3VfwPGvMFx"
      },
      "source": [
        "We'll be using the BBC dataset. These are articles collected from 5 different topics, with the data pre-processed.\n",
        "\n",
        "These data are available in the data folder (or online [here](http://mlg.ucd.ie/files/datasets/bbc.zip?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01)). The data consists of a few files. The steps we'll be following are:\n",
        "\n",
        "* *bbc.terms* is just a list of words\n",
        "* *bbc.docs* is a list of artcles listed by topic.\n",
        "\n",
        "At a high level, we're going to\n",
        "\n",
        "1. Turn the `bbc.mtx` file into a sparse matrix (a [sparse matrix](https://docs.scipy.org/doc/scipy/reference/sparse.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) format can be useful for matrices with many values that are 0, and save space by storing the position and values of non-zero elements).\n",
        "1. Decompose that sparse matrix using NMF.\n",
        "1. Use the resulting components of NMF to analyze the topics that result.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pWwxfujvMFx"
      },
      "source": [
        "## Data Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMM8KPX9vMFy"
      },
      "source": [
        "Note: This lab has been updated to work in skillsnetwork for your convenience.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gQeyg_a-vMFy"
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "# Import the urllib library for working with URLs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7mM8xjhLvMFz"
      },
      "outputs": [],
      "source": [
        "with urllib.request.urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%203/data/bbc.mtx') as r:\n",
        "    content = r.readlines()[2:]\n",
        "# Read the bbc.mtx file from a URL and store the content (excluding the first two lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP1JlmyLvMFz"
      },
      "source": [
        "## Part 1\n",
        "\n",
        "Here, we will turn this into a list of tuples representing a [sparse matrix](https://docs.scipy.org/doc/scipy/reference/sparse.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01). Remember the description of the file from above:\n",
        "\n",
        "* *bbc.mtx* is a list: first column is **wordID**, second is **articleID** and the third is the number of times that word appeared in that article.\n",
        "\n",
        "So, if word 1 appears in article 3, 2 times, one element of our list will be:\n",
        "\n",
        "`(1, 3, 2)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NBEmDCDvMF0",
        "outputId": "e1c32ad0-9651-4d00-b6e6-7435649d7221"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 1, 1),\n",
              " (1, 7, 2),\n",
              " (1, 11, 1),\n",
              " (1, 14, 1),\n",
              " (1, 15, 2),\n",
              " (1, 19, 2),\n",
              " (1, 21, 1),\n",
              " (1, 29, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "sparsemat = [tuple(map(int,map(float,c.split()))) for c in content]\n",
        "# Convert the content into a list of tuples representing a sparse matrix\n",
        "# Let's examine the first few elements\n",
        "sparsemat[:8]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvHNF_pGvMF0"
      },
      "source": [
        "## Part 2: Preparing Sparse Matrix data for NMF\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbM8lNcAvMF0"
      },
      "source": [
        "We will use the [coo matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) function to turn the sparse matrix into an array.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yjfm7H_cvMF1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.sparse import coo_matrix\n",
        "rows = [x[0] for x in sparsemat]\n",
        "cols = [x[1] for x in sparsemat]\n",
        "values = [x[2] for x in sparsemat]\n",
        "coo = coo_matrix((values, (rows, cols)))\n",
        "# Create a COO sparse matrix from the extracted rows, columns, and values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADF8unFNvMF1"
      },
      "source": [
        "## NMF\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7xocwxIvMF1"
      },
      "source": [
        "NMF is a way of decomposing a matrix of documents and words so that one of the matrices can be interpreted as the \"loadings\" or \"weights\" of each word on a topic.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixHjJ4YLvMF1"
      },
      "source": [
        "Check out [the NMF documentation](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) and the [examples of topic extraction using NMF and LDA](http://scikit-learn.org/0.18/auto_examples/applications/topics_extraction_with_nmf_lda.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpfSpya9vMF1"
      },
      "source": [
        "## Part 3\n",
        "\n",
        "Here, we will import `NMF`, define a model object with 5 components, and `fit_transform` the data created above.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOaQfk14vMF2",
        "outputId": "dda4d4c3-adf0-4657-cbb1-89ea3e764fe3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9636, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Surpress warnings from using older version of sklearn:\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "\n",
        "from sklearn.decomposition import NMF\n",
        "model = NMF(n_components=5, init='random', random_state=818)\n",
        "doc_topic = model.fit_transform(coo)\n",
        "\n",
        "doc_topic.shape\n",
        "# Perform Non-Negative Matrix Factorization (NMF) on the sparse matrix to get document-topic distributions\n",
        "# we should have 9636 observations (articles) and five latent features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlXhBD1ivMF2",
        "outputId": "76e74929-fb60-4333-b22a-1e95f21ee1b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 2, ..., 4, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# find feature with highest value per doc\n",
        "np.argmax(doc_topic, axis=1)\n",
        "# Find the topic with the highest weight for each document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNbRB6sfvMF2"
      },
      "source": [
        "## Part 4:\n",
        "\n",
        "Check out the `components` of this model:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7Or6eGlvMF2",
        "outputId": "8d86e5d7-2427-42e5-ada5-bb3eae1415af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 2226)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "model.components_.shape\n",
        "# Check the shape of the NMF components matrix (word-topic distributions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7dMcRq9vMF2"
      },
      "source": [
        "This is five rows, each of which is a \"topic\" containing the weights of each word on that topic. The exercise is to _get a list of the top 10 words for each topic_. We can just store this in a list of lists.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twYGfQUbvMF2"
      },
      "source": [
        "**Note:** Just like we read in the data above, we'll have to read in the words from the `bbc.terms` file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JXqDVJKovMF3"
      },
      "outputs": [],
      "source": [
        "with urllib.request.urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%203/data/bbc.terms') as r:\n",
        "    content = r.readlines()\n",
        "words = [c.split()[0] for c in content]\n",
        "# Read the bbc.terms file from a URL and extract the words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YS62u-k-vMF3"
      },
      "outputs": [],
      "source": [
        "topic_words = []\n",
        "for r in model.components_:\n",
        "    a = sorted([(v,i) for i,v in enumerate(r)],reverse=True)[0:12]\n",
        "    topic_words.append([words[e[1]] for e in a])\n",
        "# Get the top 12 words for each topic based on their weights in the NMF components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXhJG5ShvMF3",
        "outputId": "7aaed562-078e-40e9-c153-ffbd1c35f3e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[b'bondi',\n",
              "  b'stanlei',\n",
              "  b'continent',\n",
              "  b'mortgag',\n",
              "  b'bare',\n",
              "  b'least',\n",
              "  b'extent',\n",
              "  b'200',\n",
              "  b'leav',\n",
              "  b'frustrat',\n",
              "  b'yuan',\n",
              "  b'industri'],\n",
              " [b'manipul',\n",
              "  b'teenag',\n",
              "  b'drawn',\n",
              "  b'go',\n",
              "  b'prosecutor',\n",
              "  b'herbert',\n",
              "  b'host',\n",
              "  b'protest',\n",
              "  b'hike',\n",
              "  b'nation',\n",
              "  b'calcul',\n",
              "  b'power'],\n",
              " [b'dimens',\n",
              "  b'hous',\n",
              "  b'march',\n",
              "  b'wider',\n",
              "  b'owner',\n",
              "  b'intend',\n",
              "  b'declin',\n",
              "  b'forc',\n",
              "  b'posit',\n",
              "  b'founder',\n",
              "  b'york',\n",
              "  b'unavail'],\n",
              " [b'rome',\n",
              "  b'ft',\n",
              "  b'regain',\n",
              "  b'lawmak',\n",
              "  b'outright',\n",
              "  b'resum',\n",
              "  b'childhood',\n",
              "  b'greatest',\n",
              "  b'citi',\n",
              "  b'stagnat',\n",
              "  b'crown',\n",
              "  b'bodi'],\n",
              " [b'build',\n",
              "  b'empir',\n",
              "  b'isol',\n",
              "  b'\\xc2\\xa312',\n",
              "  b'restructur',\n",
              "  b'closer',\n",
              "  b'plung',\n",
              "  b'depreci',\n",
              "  b'durham',\n",
              "  b'race',\n",
              "  b'juli',\n",
              "  b'segreg']]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Here, each set of words relates to the corresponding topic (ie the first set of words relates to topic 'Business', etc.)\n",
        "topic_words[:5]\n",
        "# Display the top words for each topic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMJjQGxlvMF3"
      },
      "source": [
        "The original data had 5 topics, as listed in `bbc.docs` (which these topic words relate to).\n",
        "\n",
        "```\n",
        "Business\n",
        "Entertainment\n",
        "Politics\n",
        "Sport\n",
        "Tech\n",
        "```\n",
        "\n",
        "In \"real life\", we would have found a way to use these to inform the model. But for this little demo, we can just compare the recovered topics to the original ones. And they seem to match reasonably well. The order is different, which is to be expected in this kind of model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1VRdBowvMF3",
        "outputId": "6758c240-f076-4d62-cc34-7a5f2eee72c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'business.001\\n',\n",
              " b'business.002\\n',\n",
              " b'business.003\\n',\n",
              " b'business.004\\n',\n",
              " b'business.005\\n',\n",
              " b'business.006\\n',\n",
              " b'business.007\\n',\n",
              " b'business.008\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "with urllib.request.urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%203/data/bbc.docs') as r:\n",
        "    doc_content = r.readlines()\n",
        "\n",
        "doc_content[:8]\n",
        "# Read the bbc.docs file from a URL to see the original document topics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXTCP2mCvMF3"
      },
      "source": [
        "---\n",
        "### Machine Learning Foundation (C) 2020 IBM Corporation\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "name": ""
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}